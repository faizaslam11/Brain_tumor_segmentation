{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1gZUwnAiTK0E6anGQ20rSUqf5dCXaZcmD",
      "authorship_tag": "ABX9TyNDc+000P6uiKBoPuNAgoBC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/faizaslam11/Brain_tumor_segmentation/blob/main/Brain_Tumor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ys0gwX4blf5Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ed08702-7ca2-4160-df1d-fc1b78ffa628"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.6.15)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()  # Upload kaggle.json\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "S5aL9g8Elo__",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "outputId": "7fafb157-db28-4f9d-d819-18c121657c7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8ec96273-3ac2-4f77-a335-06cb37b18546\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8ec96273-3ac2-4f77-a335-06cb37b18546\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "oh5LLmQdlo9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d awsaf49/brats20-dataset-training-validation -p /content\n",
        "!unzip -q brats20-dataset-training-validation.zip -d /content/brats2020"
      ],
      "metadata": {
        "id": "VlGwLqewlo5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/content/brats2020'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "id": "8wdkEdM3lodY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Brain Tumor Segmentation using ResNet-120 + LSTM\n",
        "# PhD Research Project - BraTS 2020 Dataset\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Deep Learning Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet101\n",
        "\n",
        "# Medical Imaging\n",
        "import nibabel as nib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "# Visualization\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"Libraries imported successfully!\")"
      ],
      "metadata": {
        "id": "Z7W6rY2bVAJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 1. DATASET EXPLORATION AND SETUP\n",
        "# =============================================================================\n",
        "\n",
        "# In Kaggle, the dataset path is typically:\n",
        "# DATASET_PATH = \"/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData\"\n",
        "DATASET_PATH = \"/content/brats2020/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData\"\n",
        "\n",
        "# Dataset structure exploration\n",
        "def explore_dataset_structure():\n",
        "    \"\"\"Explore the actual structure of BraTS dataset\"\"\"\n",
        "    print(\"=== EXPLORING DATASET STRUCTURE ===\")\n",
        "\n",
        "    if not os.path.exists(DATASET_PATH):\n",
        "        print(\"Dataset not found!\")\n",
        "        return None, None\n",
        "\n",
        "    print(f\"Dataset root: {DATASET_PATH}\")\n",
        "    root_contents = os.listdir(DATASET_PATH)\n",
        "    print(f\"Root contents: {root_contents}\")\n",
        "\n",
        "    # BraTS dataset typically has this structure:\n",
        "    # /BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001/\n",
        "    # Let's search for the actual patient folders\n",
        "\n",
        "    train_path = None\n",
        "    patient_folders = []\n",
        "\n",
        "    # Search recursively for patient folders containing .nii.gz files\n",
        "    print(\"Searching for patient folders with .nii.gz files...\")\n",
        "\n",
        "    for root, dirs, files in os.walk(DATASET_PATH):\n",
        "        # Check if this directory contains .nii.gz files\n",
        "        # nii_files = [f for f in files if f.endswith('.nii.gz')]\n",
        "        nii_files = [f for f in files if f.endswith('.nii.gz') or f.endswith('.nii')]\n",
        "\n",
        "        if nii_files:\n",
        "            # This is likely a patient folder\n",
        "            patient_folder_name = os.path.basename(root)\n",
        "            parent_dir = os.path.dirname(root)\n",
        "\n",
        "            if patient_folder_name.startswith('BraTS'):\n",
        "                if train_path is None:\n",
        "                    train_path = parent_dir\n",
        "                    print(f\"Found training data directory: {train_path}\")\n",
        "\n",
        "                patient_folders.append(patient_folder_name)\n",
        "                print(f\"Found patient folder: {patient_folder_name} with {len(nii_files)} .nii.gz files\")\n",
        "\n",
        "                # Show files in first patient folder\n",
        "                if len(patient_folders) == 1:\n",
        "                    print(f\"Sample files in {patient_folder_name}:\")\n",
        "                    for f in nii_files[:10]:  # Show first 10 files\n",
        "                        print(f\"  {f}\")\n",
        "\n",
        "    if train_path and patient_folders:\n",
        "        print(f\"\\nSUMMARY:\")\n",
        "        print(f\"Training data path: {train_path}\")\n",
        "        print(f\"Total patient folders found: {len(patient_folders)}\")\n",
        "        print(f\"Sample patients: {patient_folders[:5]}\")\n",
        "        return train_path, patient_folders\n",
        "    else:\n",
        "        print(\"Could not find patient folders with .nii.gz files!\")\n",
        "\n",
        "        # Let's explore the structure manually\n",
        "        print(\"\\nManual exploration:\")\n",
        "        base_train_path = os.path.join(DATASET_PATH, \"BraTS2020_TrainingData\")\n",
        "        if os.path.exists(base_train_path):\n",
        "            print(f\"Contents of {base_train_path}:\")\n",
        "            for item in os.listdir(base_train_path):\n",
        "                item_path = os.path.join(base_train_path, item)\n",
        "                if os.path.isdir(item_path):\n",
        "                    print(f\"  Directory: {item}\")\n",
        "                    sub_contents = os.listdir(item_path)[:10]  # First 10 items\n",
        "                    for sub_item in sub_contents:\n",
        "                        sub_path = os.path.join(item_path, sub_item)\n",
        "                        if os.path.isdir(sub_path):\n",
        "                            print(f\"    Subdirectory: {sub_item}\")\n",
        "                            # Check if this contains .nii.gz files\n",
        "                            try:\n",
        "                                files_in_sub = os.listdir(sub_path)\n",
        "                                nii_count = len([f for f in files_in_sub if f.endswith('.nii.gz')])\n",
        "                                if nii_count > 0:\n",
        "                                    print(f\"      Contains {nii_count} .nii.gz files\")\n",
        "                                    return sub_path if train_path is None else train_path, [sub_item]\n",
        "                            except:\n",
        "                                pass\n",
        "\n",
        "        return None, None\n",
        "\n",
        "# Run exploration\n",
        "train_path, patient_folders = explore_dataset_structure()"
      ],
      "metadata": {
        "id": "hGdfsVlfVXO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class BraTSDataLoader:\n",
        "    def __init__(self, data_path, subset_size=10):\n",
        "        \"\"\"\n",
        "        Initialize BraTS data loader\n",
        "        Args:\n",
        "            data_path: Path to BraTS training data\n",
        "            subset_size: Number of patients to use (for memory constraints)\n",
        "        \"\"\"\n",
        "\n",
        "        self.data_path = data_path\n",
        "        self.subset_size = subset_size\n",
        "\n",
        "        # Get actual patient folders\n",
        "        all_folders = os.listdir(data_path) if os.path.exists(data_path) else []\n",
        "        self.patient_folders = [f for f in all_folders if 'BraTS' in f][:subset_size]\n",
        "        print(\"Patient folders being used:\", self.patient_folders)\n",
        "        print(f\"Using {len(self.patient_folders)} patients for training\")\n",
        "\n",
        "        if not self.patient_folders:\n",
        "            print(\"No patient folders found!\")\n",
        "            return\n",
        "\n",
        "        # Auto-detect file naming pattern\n",
        "        self.file_pattern = self._detect_file_pattern()\n",
        "\n",
        "    def _detect_file_pattern(self):\n",
        "        \"\"\"Auto-detect the file naming pattern in BraTS dataset\"\"\"\n",
        "        if not self.patient_folders:\n",
        "            return None\n",
        "        sample_patient = self.patient_folders[0]\n",
        "        sample_path = os.path.join(self.data_path, sample_patient)\n",
        "\n",
        "        if not os.path.exists(sample_path):\n",
        "            return None\n",
        "        files = os.listdir(sample_path)\n",
        "        nii_files = [f for f in files if f.endswith('.nii') or f.endswith('.nii.gz')]\n",
        "        print(f\"Sample patient files: {nii_files}\")\n",
        "        # Check for standard naming like BraTS20_Training_001_flair.nii.gz\n",
        "        test_file_nii = f\"{sample_patient}_flair.nii\"\n",
        "        test_file_nizz = f\"{sample_patient}_flair.nii.gz\"\n",
        "        if test_file_nii in nii_files or test_file_niigz in nii_files:\n",
        "            print(\"✅ Detected standard BraTS naming convention.\")\n",
        "            return lambda patient_id, modality: f\"{patient_id}_{modality}.nii.gz\"\n",
        "\t\t# Otherwise fallback to flexible pattern matching\n",
        "        else:\n",
        "            print(\"⚠️ Using flexible file pattern matching.\")\n",
        "            return lambda patient_id, modality: self._find_modality_file(\n",
        "            os.path.join(self.data_path, patient_id), modality\n",
        "    )\n",
        "    def _find_modality_file(self, patient_path, modality):\n",
        "        \"\"\"Find file by modality name in the filename\"\"\"\n",
        "        files = os.listdir(patient_path)\n",
        "        for file in files:\n",
        "            if modality.lower() in file.lower() and file.endswith('.nii.gz'):\n",
        "                return file\n",
        "        return None\n",
        "\n",
        "    def _flexible_pattern(self, patient_id, modality):\n",
        "        \"\"\"Flexible pattern matching\"\"\"\n",
        "        patient_path = os.path.join(self.data_path, patient_id)\n",
        "        return self._find_modality_file(patient_path, modality)\n",
        "\n",
        "    def load_patient_data(self, patient_id):\n",
        "        \"\"\"Load all modalities for a single patient\"\"\"\n",
        "        patient_path = os.path.join(self.data_path, patient_id)\n",
        "\n",
        "        if not os.path.exists(patient_path):\n",
        "            print(f\"Patient path not found: {patient_path}\")\n",
        "            return {}\n",
        "\n",
        "        # Try to find files for each modality\n",
        "        modalities = ['flair', 't1', 't1ce', 't2', 'seg']\n",
        "        files = {}\n",
        "\n",
        "        for modality in modalities:\n",
        "            filename = None\n",
        "            if self.file_pattern:\n",
        "                filename = self.file_pattern(patient_id, modality)\n",
        "                if filename:\n",
        "                    # filepath = os.path.join(patient_path, filename)\n",
        "                    nii_gz_path = os.path.join(patient_path, filename)\n",
        "                    nii_path = nii_gz_path.replace(\".nii.gz\", \".nii\")\n",
        "                    if os.path.exists(nii_gz_path):\n",
        "                        files[modality] = nii_gz_path\n",
        "                    elif os.path.exists(nii_path):\n",
        "                        files[modality] = nii_path\n",
        "                    else:\n",
        "                        print(f\"[Missing] {modality.upper()} not found at {nii_gz_path} or {nii_path}\")\n",
        "                else:\n",
        "                    print(f\"[Pattern Fail] Could not generate filename for {modality} using pattern.\")\n",
        "\n",
        "        # Load the data\n",
        "        data = {}\n",
        "        for modality, filepath in files.items():\n",
        "            try:\n",
        "                nii_img = nib.load(filepath)\n",
        "                data[modality] = nii_img.get_fdata()\n",
        "                print(f\"Loaded {modality}: {data[modality].shape}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {filepath}: {e}\")\n",
        "\n",
        "        return data\n",
        "\n",
        "    def preprocess_volume(self, volume, target_size=(128, 128), is_mask=False):\n",
        "        \"\"\"Preprocess 3D volume to 2D slices\"\"\"\n",
        "        # Normalize to 0-1 range\n",
        "        if not is_mask:\n",
        "            volume = (volume - volume.min()) / (volume.max() - volume.min() + 1e-8)\n",
        "\n",
        "        processed_slices = []\n",
        "        for slice_idx in range(volume.shape[2]):\n",
        "            slice_2d = volume[:, :, slice_idx]\n",
        "\n",
        "            # Resize slice\n",
        "            if is_mask:\n",
        "                slice_resized = cv2.resize(slice_2d, target_size, interpolation=cv2.INTER_NEAREST)\n",
        "            else:\n",
        "                slice_resized = cv2.resize(slice_2d, target_size, interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "            processed_slices.append(slice_resized)\n",
        "\n",
        "        return np.array(processed_slices)\n",
        "\n",
        "    def create_dataset(self):\n",
        "        \"\"\"Create dataset with all patients\"\"\"\n",
        "        all_sequences = []\n",
        "        all_masks = []\n",
        "\n",
        "        for patient_id in tqdm(self.patient_folders, desc=\"Processing patients\"):\n",
        "            try:\n",
        "                patient_data = self.load_patient_data(patient_id)\n",
        "\n",
        "                if all(mod in patient_data for mod in ['flair', 't1ce', 'seg']):\n",
        "                    # Process each modality\n",
        "                    flair_slices = self.preprocess_volume(patient_data['flair'])\n",
        "                    t1ce_slices = self.preprocess_volume(patient_data['t1ce'])\n",
        "                    seg_slices = self.preprocess_volume(patient_data['seg'], is_mask=True)\n",
        "                    seg_slices[seg_slices == 4] = 3\n",
        "                    # Combine modalities (using FLAIR and T1CE as example)\n",
        "                    combined_slices = np.stack([flair_slices, t1ce_slices], axis=1)\n",
        "\n",
        "                    # Filter out empty slices (slices with no tumor)\n",
        "                    for i in range(len(seg_slices)):\n",
        "                        print(f\"[{patient_id}] Slice {i} sum: {np.sum(seg_slices[i])}\")\n",
        "                        # if np.sum(seg_slices[i]) > 0:  # Has tumor pixels\n",
        "                        all_sequences.append(combined_slices[i])\n",
        "                        all_masks.append(seg_slices[i])\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {patient_id}: {e}\")\n",
        "                continue\n",
        "\n",
        "        return np.array(all_sequences), np.array(all_masks)"
      ],
      "metadata": {
        "id": "7hrPMNoQVgNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize with 50 patients\n",
        "data_loader = BraTSDataLoader(data_path=train_path, subset_size=50)\n",
        "\n",
        "# Actually load and preprocess the data\n",
        "sequences, masks = data_loader.create_dataset()\n",
        "\n",
        "# Print summarys\n",
        "print(f\"\\n✅ Final dataset shapes:\")\n",
        "print(f\"Sequences shape: {sequences.shape}\")\n",
        "print(f\"Masks shape: {masks.shape}\")\n"
      ],
      "metadata": {
        "id": "nO8LITFvV4eY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BraTSDataset(Dataset):\n",
        "    def __init__(self, sequences, masks, sequence_length=8):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            sequences: 4D array (num_slices, channels, height, width)\n",
        "            masks: 3D array (num_slices, height, width)\n",
        "            sequence_length: Number of consecutive slices for LSTM\n",
        "        \"\"\"\n",
        "        self.sequences = sequences\n",
        "        self.masks = masks\n",
        "        self.sequence_length = sequence_length\n",
        "\n",
        "        # Create sequence indices\n",
        "        self.valid_indices = []\n",
        "        current_patient_slices = 0\n",
        "\n",
        "        for i in range(len(sequences) - sequence_length + 1):\n",
        "            # Check if we have enough consecutive slices\n",
        "            if current_patient_slices >= sequence_length - 1:\n",
        "                self.valid_indices.append(i - sequence_length + 1)\n",
        "            current_patient_slices += 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.valid_indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        start_idx = self.valid_indices[idx]\n",
        "\n",
        "        # Get sequence of slices\n",
        "        sequence = self.sequences[start_idx:start_idx + self.sequence_length]\n",
        "        mask = self.masks[start_idx + self.sequence_length - 1]  # Predict last slice\n",
        "\n",
        "        # Convert to tensors\n",
        "        sequence = torch.FloatTensor(sequence)\n",
        "        mask = torch.LongTensor(mask)\n",
        "\n",
        "        return sequence, mask"
      ],
      "metadata": {
        "id": "6i06lUuNV7bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_transform = A.Compose([\n",
        "#     A.HorizontalFlip(p=0.5),\n",
        "#     A.VerticalFlip(p=0.5),\n",
        "#     A.RandomRotate90(p=0.5),\n",
        "#     A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
        "#     A.GaussianBlur(p=0.2),\n",
        "#     A.RandomBrightnessContrast(p=0.2),\n",
        "#     A.Normalize(mean=(0.5, 0.5), std=(0.5, 0.5)),\n",
        "#     ToTensorV2()\n",
        "# ])\n",
        "\n",
        "# val_transform = A.Compose([\n",
        "#     A.Normalize(mean=(0.5, 0.5), std=(0.5, 0.5)),\n",
        "#     ToTensorV2()\n",
        "# ])\n"
      ],
      "metadata": {
        "id": "YxVzdGkrZiP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet120Backbone(nn.Module):\n",
        "    def __init__(self, input_channels=2, pretrained=True):\n",
        "        super(ResNet120Backbone, self).__init__()\n",
        "\n",
        "        # Start with ResNet-101 and modify\n",
        "        resnet = resnet101(pretrained=pretrained)\n",
        "\n",
        "        # Modify first conv layer for multi-channel input\n",
        "        self.conv1 = nn.Conv2d(input_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        if pretrained:\n",
        "            # Initialize new conv layer with pretrained weights (average across channels)\n",
        "            with torch.no_grad():\n",
        "                self.conv1.weight = nn.Parameter(\n",
        "                    resnet.conv1.weight.mean(dim=1, keepdim=True).repeat(1, input_channels, 1, 1)\n",
        "                )\n",
        "\n",
        "        # Copy other layers from ResNet-101\n",
        "        self.bn1 = resnet.bn1\n",
        "        self.relu = resnet.relu\n",
        "        self.maxpool = resnet.maxpool\n",
        "\n",
        "        self.layer1 = resnet.layer1\n",
        "        self.layer2 = resnet.layer2\n",
        "        self.layer3 = resnet.layer3\n",
        "        self.layer4 = resnet.layer4\n",
        "\n",
        "        # Add additional layers to make it ResNet-120\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(2048, 2048, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(2048),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(2048, 2048, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(2048),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.layer5(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        return x\n",
        "\n",
        "class ResNet120LSTM(nn.Module):\n",
        "    def __init__(self, input_channels=2, num_classes=4, hidden_size=512, num_layers=2,pretrained=False):\n",
        "        super(ResNet120LSTM, self).__init__()\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # ResNet backbone for feature extraction\n",
        "        self.backbone = ResNet120Backbone(input_channels, pretrained=pretrained)\n",
        "        backbone_output_size = 2048\n",
        "\n",
        "        # Bidirectional LSTM\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=backbone_output_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "            dropout=0.3\n",
        "        )\n",
        "\n",
        "        # Classification head for segmentation\n",
        "        lstm_output_size = hidden_size * 2  # bidirectional\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(lstm_output_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128 * 128 * num_classes)  # Output for 128x128 segmentation\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len, channels, height, width = x.shape\n",
        "\n",
        "        # Process each slice through ResNet backbone\n",
        "        features = []\n",
        "        for i in range(seq_len):\n",
        "            slice_features = self.backbone(x[:, i])\n",
        "            features.append(slice_features)\n",
        "\n",
        "        # Stack features for LSTM input\n",
        "        features = torch.stack(features, dim=1)  # (batch, seq_len, feature_dim)\n",
        "\n",
        "        # LSTM processing\n",
        "        lstm_out, _ = self.lstm(features)\n",
        "\n",
        "        # Use the last output for segmentation\n",
        "        last_output = lstm_out[:, -1, :]  # (batch, hidden_size*2)\n",
        "\n",
        "        # Generate segmentation map\n",
        "        segmentation = self.classifier(last_output)\n",
        "        segmentation = segmentation.view(batch_size, self.num_classes, 128, 128)\n",
        "\n",
        "        return segmentation"
      ],
      "metadata": {
        "id": "_tUVqKg2Zkxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coefficient(pred, target, smooth=1e-6):\n",
        "    \"\"\"Calculate Dice coefficient\"\"\"\n",
        "    pred = torch.softmax(pred, dim=1)\n",
        "    pred = torch.argmax(pred, dim=1)\n",
        "\n",
        "    dice_scores = []\n",
        "    for class_idx in range(1, 4):  # Classes 1, 2, 3 (excluding background)\n",
        "        pred_class = (pred == class_idx).float()\n",
        "        target_class = (target == class_idx).float()\n",
        "\n",
        "        intersection = (pred_class * target_class).sum()\n",
        "        union = pred_class.sum() + target_class.sum()\n",
        "\n",
        "        dice = (2. * intersection + smooth) / (union + smooth)\n",
        "        dice_scores.append(dice.item())\n",
        "\n",
        "    return np.mean(dice_scores)\n",
        "\n",
        "def combined_loss(pred, target, alpha=0.5):\n",
        "    \"\"\"Combine Cross Entropy and Dice Loss\"\"\"\n",
        "    ce_loss = nn.CrossEntropyLoss()(pred, target)\n",
        "\n",
        "    # Dice loss\n",
        "    pred_soft = torch.softmax(pred, dim=1)\n",
        "    dice_loss = 0\n",
        "    for class_idx in range(1, 4):\n",
        "        pred_class = pred_soft[:, class_idx]\n",
        "        target_class = (target == class_idx).float()\n",
        "\n",
        "        intersection = (pred_class * target_class).sum()\n",
        "        union = pred_class.sum() + target_class.sum()\n",
        "        dice = (2. * intersection + 1e-6) / (union + 1e-6)\n",
        "        dice_loss += (1 - dice)\n",
        "\n",
        "    dice_loss /= 3  # Average over classes\n",
        "\n",
        "    return alpha * ce_loss + (1 - alpha) * dice_loss\n"
      ],
      "metadata": {
        "id": "Eu-BybTIZshq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import FileLink\n",
        "checkpoint_path='checkpoint_epoch_last.pth'\n",
        "\n",
        "def train_model(model, train_loader, val_loader, num_epochs=12, learning_rate=0.001, checkpoint_path='checkpoint_epoch_last.pth'):\n",
        "    \"\"\"Train the ResNet-120 + LSTM model\"\"\"\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Training on device: {device}\")\n",
        "\n",
        "    model = model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "# Resume training if checkpoint exists\n",
        "    resume_epoch = 0\n",
        "    total_epochs = num_epochs\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_dice_scores = []\n",
        "    val_dice_scores = []\n",
        "\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        print(f\"🔁 Resuming from checkpoint: {checkpoint_path}\")\n",
        "        checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "        resume_epoch = checkpoint['epoch'] + 1\n",
        "        print(f\"Resuming from epoch {resume_epoch}\")\n",
        "      # 🔁 Load previous history if available\n",
        "        train_losses = checkpoint.get('train_losses', [])\n",
        "        val_losses = checkpoint.get('val_losses', [])\n",
        "        train_dice_scores = checkpoint.get('train_dice_scores', [])\n",
        "        val_dice_scores = checkpoint.get('val_dice_scores', [])\n",
        "        print(f\"✅ Resuming training from epoch {resume_epoch}\")\n",
        "    else:\n",
        "        print(\"🆕 No checkpoint found. Starting fresh training.\")\n",
        "\n",
        "    for epoch in range(resume_epoch, num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_dice = 0.0\n",
        "\n",
        "        for batch_idx, (sequences, masks) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")):\n",
        "            sequences, masks = sequences.to(device), masks.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(sequences)\n",
        "            loss = combined_loss(outputs, masks)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            train_dice += dice_coefficient(outputs, masks)\n",
        "\n",
        "            if batch_idx % 10 == 0:\n",
        "                print(f'Batch {batch_idx}, Loss: {loss.item():.4f}')\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_dice = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for sequences, masks in val_loader:\n",
        "                sequences, masks = sequences.to(device), masks.to(device)\n",
        "                outputs = model(sequences)\n",
        "                loss = combined_loss(outputs, masks)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                val_dice += dice_coefficient(outputs, masks)\n",
        "\n",
        "        # Calculate averages\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        avg_train_dice = train_dice / len(train_loader)\n",
        "        avg_val_dice = val_dice / len(val_loader)\n",
        "\n",
        "        train_losses.append(avg_train_loss)\n",
        "        val_losses.append(avg_val_loss)\n",
        "        train_dice_scores.append(avg_train_dice)\n",
        "        val_dice_scores.append(avg_val_dice)\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
        "        print(f'  Train Loss: {avg_train_loss:.4f}, Train Dice: {avg_train_dice:.4f}')\n",
        "        print(f'  Val Loss: {avg_val_loss:.4f}, Val Dice: {avg_val_dice:.4f}')\n",
        "\n",
        "        scheduler.step()\n",
        "    # Save checkpoint\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'train_losses': train_losses,\n",
        "            'val_losses': val_losses,\n",
        "            'train_dice_scores': train_dice_scores,\n",
        "            'val_dice_scores': val_dice_scores\n",
        "        }, checkpoint_path)\n",
        "        print(f\"✅ Checkpoint saved at epoch {epoch+1}\")\n",
        "        try:\n",
        "            display(FileLink(checkpoint_path))\n",
        "            print(\"Click below to download the checkpoint manually (before session ends):\")\n",
        "        except:\n",
        "            print(\" Could not create FileLink. Run this cell in an interactive environment.\")\n",
        "\n",
        "    print(\"✅ Training complete.\")\n",
        "    return {\n",
        "        'train_losses': train_losses,\n",
        "        'val_losses': val_losses,\n",
        "        'train_dice_scores': train_dice_scores,\n",
        "        'val_dice_scores': val_dice_scores,\n",
        "        'resume_epoch': resume_epoch\n",
        "        }"
      ],
      "metadata": {
        "id": "CD_rpEhHZvR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_results(model, dataset, device, num_samples=5):\n",
        "    \"\"\"Visualize segmentation results\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    fig, axes = plt.subplots(3, num_samples, figsize=(15, 9))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(num_samples):\n",
        "            sequences, true_mask = dataset[i]\n",
        "            print(f\"[Sample {i}] True mask unique values:\", np.unique(true_mask.numpy()))\n",
        "            sequences = sequences.unsqueeze(0).to(device)\n",
        "\n",
        "            # Get prediction\n",
        "            pred = model(sequences)\n",
        "            pred_mask = torch.softmax(pred, dim=1)\n",
        "            pred_mask = torch.argmax(pred_mask, dim=1).cpu().numpy()[0]\n",
        "\n",
        "            # Original image (FLAIR channel)\n",
        "            original = sequences[0, -1, 0].cpu().numpy()\n",
        "            true_mask = true_mask.numpy()\n",
        "\n",
        "            # Plot\n",
        "            axes[0, i].imshow(original, cmap='gray')\n",
        "            axes[0, i].set_title(f'Original {i+1}')\n",
        "            axes[0, i].axis('off')\n",
        "\n",
        "            axes[1, i].imshow(true_mask, cmap='jet')\n",
        "            axes[1, i].set_title(f'True Mask {i+1}')\n",
        "            axes[1, i].axis('off')\n",
        "\n",
        "            axes[2, i].imshow(pred_mask, cmap='jet')\n",
        "            axes[2, i].set_title(f'Predicted {i+1}')\n",
        "            axes[2, i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_training_curves(history):\n",
        "    \"\"\"Plot training curves\"\"\"\n",
        "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 8))\n",
        "\n",
        "    # Loss curves\n",
        "    ax1.plot(history['train_losses'], label='Train Loss')\n",
        "    ax1.plot(history['val_losses'], label='Validation Loss')\n",
        "    ax1.set_title('Training and Validation Loss')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True)\n",
        "\n",
        "    # Dice score curves\n",
        "    ax2.plot(history['train_dice_scores'], label='Train Dice')\n",
        "    ax2.plot(history['val_dice_scores'], label='Validation Dice')\n",
        "    ax2.set_title('Training and Validation Dice Score')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Dice Score')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True)\n",
        "\n",
        "    # Loss difference\n",
        "    loss_diff = np.array(history['val_losses']) - np.array(history['train_losses'])\n",
        "    ax3.plot(loss_diff)\n",
        "    ax3.set_title('Validation - Training Loss (Overfitting Check)')\n",
        "    ax3.set_xlabel('Epoch')\n",
        "    ax3.set_ylabel('Loss Difference')\n",
        "    ax3.grid(True)\n",
        "\n",
        "    # Dice improvement\n",
        "    dice_improvement = np.array(history['val_dice_scores']) - history['val_dice_scores'][0]\n",
        "    ax4.plot(dice_improvement)\n",
        "    ax4.set_title('Validation Dice Score Improvement')\n",
        "    ax4.set_xlabel('Epoch')\n",
        "    ax4.set_ylabel('Dice Improvement')\n",
        "    ax4.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "WJOfh9RAZxtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def main():\n",
        "    \"\"\"Main execution function\"\"\"\n",
        "    print(\"Starting Brain Tumor Segmentation Training...\")\n",
        "\n",
        "    # First, explore dataset structure\n",
        "    train_path, patient_folders = explore_dataset_structure()\n",
        "#     train_path = \"/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData\"\n",
        "# patient_folders = os.listdir(train_path)\n",
        "\n",
        "\n",
        "    if not train_path or not patient_folders:\n",
        "        print(\"ERROR: Could not find proper dataset structure!\")\n",
        "        print(\"Please check that the BraTS dataset is properly added to your Kaggle notebook.\")\n",
        "        return\n",
        "\n",
        "    # Load and preprocess data\n",
        "    print(\"\\nLoading and preprocessing data...\")\n",
        "    data_loader = BraTSDataLoader(\n",
        "        data_path=train_path,\n",
        "        subset_size=50\n",
        "    )\n",
        "\n",
        "    if not data_loader.patient_folders:\n",
        "        print(\"ERROR: No patient folders found!\")\n",
        "        return\n",
        "\n",
        "    sequences, masks = data_loader.create_dataset()\n",
        "    print(f\"Dataset created: {sequences.shape} sequences, {masks.shape} masks\")\n",
        "\n",
        "    if len(sequences) == 0:\n",
        "        print(\"ERROR: No data loaded!\")\n",
        "        print(\"This might be due to:\")\n",
        "        print(\"1. Incorrect file naming pattern\")\n",
        "        print(\"2. Missing modality files\")\n",
        "        print(\"3. Empty/corrupt data files\")\n",
        "        return\n",
        "\n",
        "    print(\"SUCCESS: Data loaded successfully!\")\n",
        "    print(f\"Total sequences: {len(sequences)}\")\n",
        "    print(f\"Sequence shape: {sequences[0].shape}\")\n",
        "    print(f\"Mask shape: {masks[0].shape}\")\n",
        "\n",
        "    # If we reach here, data loading works - continue with training\n",
        "    # For now, let's just test with a tiny dataset\n",
        "    if len(sequences) < 10 or sequences.shape[0] < 8:\n",
        "        print(\"❗ Not enough sequences for training. Increase subset_size or reduce sequence_length.\")\n",
        "        return\n",
        "        # print(f\"Warning: Only {len(sequences)} sequences available. Need more data for proper training.\")\n",
        "        # print(\"Consider increasing subset_size or checking data quality.\")\n",
        "        # return\n",
        "\n",
        "    # Create train/validation split\n",
        "    train_sequences, val_sequences, train_masks, val_masks = train_test_split(\n",
        "        sequences, masks, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Create datasets and dataloaders\n",
        "    train_dataset = BraTSDataset(train_sequences, train_masks, sequence_length=8)\n",
        "    val_dataset = BraTSDataset(val_sequences, val_masks, sequence_length=8)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=2)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, num_workers=2)\n",
        "\n",
        "    print(f\"Training samples: {len(train_dataset)}\")\n",
        "    print(f\"Validation samples: {len(val_dataset)}\")\n",
        "\n",
        "    print(\"🔍 Checking unique values in validation masks:\")\n",
        "    for i in range(5):\n",
        "        _, true_mask = val_dataset[i]\n",
        "        print(f\"[Sample {i}] Unique labels in mask:\", np.unique(true_mask.numpy()))\n",
        "\n",
        "    # Initialize model\n",
        "    model = ResNet120LSTM(input_channels=2, num_classes=4, pretrained=False)\n",
        "\n",
        "    # Train model\n",
        "    print(\"Starting training...\")\n",
        "    history = train_model(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        num_epochs=12\n",
        "        ,\n",
        "        learning_rate=0.001,\n",
        "        checkpoint_path='checkpoint.pth'\n",
        "    )\n",
        "    print(\"Training resumed from epoch:\", history.get('resume_epoch', 0))\n",
        "    # Plot results\n",
        "    plot_training_curves(history)\n",
        "\n",
        "    # Visualize some results\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    visualize_results(model, val_dataset, device, num_samples=5)\n",
        "\n",
        "    # Save model\n",
        "    torch.save(model.state_dict(), 'resnet120_lstm_brain_tumor.pth')\n",
        "    print(\"Model saved as 'resnet120_lstm_brain_tumor.pth'\")\n",
        "\n",
        "    print(\"Training completed successfully!\")\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "j-Iz776YZ0TK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rWvecP2M4rO0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}